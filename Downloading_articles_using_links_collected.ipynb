{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (OperationalError('unable to open database file',)).History will not be written to the database."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread IPythonHistorySavingThread:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/ruoyangzhang/anaconda3/lib/python3.6/site-packages/IPython/core/history.py\", line 834, in run\n",
      "  File \"<decorator-gen-23>\", line 2, in writeout_cache\n",
      "  File \"/Users/ruoyangzhang/anaconda3/lib/python3.6/site-packages/IPython/core/history.py\", line 58, in needs_sqlite\n",
      "  File \"/Users/ruoyangzhang/anaconda3/lib/python3.6/site-packages/IPython/core/history.py\", line 780, in writeout_cache\n",
      "  File \"/Users/ruoyangzhang/anaconda3/lib/python3.6/site-packages/IPython/core/history.py\", line 764, in _writeout_input_cache\n",
      "sqlite3.OperationalError: unable to open database file\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/ruoyangzhang/anaconda3/lib/python3.6/site-packages/ipykernel/iostream.py\", line 97, in _event_pipe\n",
      "AttributeError: '_thread._local' object has no attribute 'event_pipe'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/ruoyangzhang/anaconda3/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "  File \"<decorator-gen-24>\", line 2, in run\n",
      "  File \"/Users/ruoyangzhang/anaconda3/lib/python3.6/site-packages/IPython/core/history.py\", line 58, in needs_sqlite\n",
      "  File \"/Users/ruoyangzhang/anaconda3/lib/python3.6/site-packages/IPython/core/history.py\", line 837, in run\n",
      "  File \"/Users/ruoyangzhang/anaconda3/lib/python3.6/site-packages/ipykernel/iostream.py\", line 376, in write\n",
      "  File \"/Users/ruoyangzhang/anaconda3/lib/python3.6/site-packages/ipykernel/iostream.py\", line 203, in schedule\n",
      "  File \"/Users/ruoyangzhang/anaconda3/lib/python3.6/site-packages/ipykernel/iostream.py\", line 101, in _event_pipe\n",
      "  File \"/Users/ruoyangzhang/anaconda3/lib/python3.6/site-packages/zmq/sugar/context.py\", line 146, in socket\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 285, in zmq.backend.cython.socket.Socket.__cinit__\n",
      "zmq.error.ZMQError: Too many open files\n",
      "Unhandled exception in thread started by <bound method Thread._bootstrap of <HistorySavingThread(IPythonHistorySavingThread, started 123145498206208)>>\n"
     ]
    }
   ],
   "source": [
    "from newspaper import Article\n",
    "import pickle\n",
    "from multiprocessing import Pool\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import requests\n",
    "import random\n",
    "from time import time\n",
    "\n",
    "\n",
    "\n",
    "data_path = '/Users/ruoyangzhang/Documents/PythonWorkingDirectory/news_exploration/Data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### loading in the article links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(data_path + 'article_links.pickle', 'rb') as handle:\n",
    "    article_links = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "it seems as though there are many broken links (404 errors), we wish to estimate how many there are using a random sampling and then using the requests package to test if we receive a good response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_response(link):\n",
    "    if not requests.get(link).ok:\n",
    "        return(1)\n",
    "    else:\n",
    "        return(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_idx = random.sample(range(len(article_links)),500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/500 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████| 500/500 [00:00<00:00, 63540.43it/s]\u001b[A"
     ]
    }
   ],
   "source": [
    "p = Pool(7, maxtasksperchild = 1)\n",
    "test_res = p.map(check_response, tqdm([article_links[i] for i in sample_idx]))\n",
    "p.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the estimated percentage of broken links is: 32.0 percent\n"
     ]
    }
   ],
   "source": [
    "print('the estimated percentage of broken links is:' ,100*(sum(test_res)/500), 'percent')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## downloading the articles\n",
    "32% seems acceptable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try downloading the first 1k articles in the list to see if we get blocked and to time the entire process to estimate how long it would take for the entire dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_article_to_dict(link):\n",
    "    if requests.get(link).ok:\n",
    "        dict_to_return = {}\n",
    "        article = Article(link)\n",
    "        article.download()\n",
    "        article.parse()\n",
    "        dict_to_return['author'] = article.authors\n",
    "        dict_to_return['title'] = article.title\n",
    "        dict_to_return['publish_date'] = article.publish_date\n",
    "        dict_to_return['text'] = article.text\n",
    "        dict_to_return['images_url'] = ' '.join(list(article.images))\n",
    "        dict_to_return['description'] = article.meta_description\n",
    "        dict_to_return['lang'] = article.meta_lang\n",
    "        return(dict_to_return)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/100000 [00:00<?, ?it/s]\u001b[A\n",
      " 28%|██▊       | 28125/100000 [02:27<06:16, 190.81it/s]\u001b[A\n",
      " 31%|███▏      | 31250/100000 [02:29<05:28, 209.25it/s]\u001b[A\n",
      " 34%|███▍      | 34375/100000 [02:29<04:45, 229.53it/s]\u001b[A\n",
      " 38%|███▊      | 37500/100000 [02:31<04:13, 246.79it/s]\u001b[A\n",
      " 44%|████▍     | 43750/100000 [02:32<03:16, 286.72it/s]\u001b[A\n",
      " 53%|█████▎    | 53125/100000 [02:34<02:16, 343.50it/s]\u001b[A\n",
      " 56%|█████▋    | 56250/100000 [02:35<02:00, 362.49it/s]\u001b[A\n",
      " 59%|█████▉    | 59375/100000 [02:35<01:46, 381.36it/s]\u001b[A\n",
      " 62%|██████▎   | 62500/100000 [02:37<01:34, 397.24it/s]\u001b[A\n",
      " 66%|██████▌   | 65625/100000 [02:37<01:22, 416.00it/s]\u001b[A\n",
      " 66%|██████▌   | 65625/100000 [02:51<01:29, 382.99it/s]\u001b[A\n",
      " 69%|██████▉   | 68750/100000 [07:59<03:37, 143.53it/s]\u001b[A\n",
      " 72%|███████▏  | 71875/100000 [08:14<03:13, 145.40it/s]\u001b[A\n",
      " 75%|███████▌  | 75000/100000 [08:17<02:45, 150.84it/s]\u001b[A\n",
      " 78%|███████▊  | 78125/100000 [08:20<02:20, 156.12it/s]\u001b[A\n",
      " 81%|████████▏ | 81250/100000 [08:20<01:55, 162.27it/s]\u001b[A\n",
      " 84%|████████▍ | 84375/100000 [08:21<01:32, 168.23it/s]\u001b[A\n",
      " 88%|████████▊ | 87500/100000 [08:21<01:11, 174.39it/s]\u001b[A\n",
      " 91%|█████████ | 90625/100000 [08:26<00:52, 178.75it/s]\u001b[A\n",
      " 91%|█████████ | 90625/100000 [08:41<00:53, 173.80it/s]\u001b[A\n",
      " 94%|█████████▍| 93750/100000 [12:42<00:50, 122.94it/s]\u001b[A\n",
      " 94%|█████████▍| 93750/100000 [13:01<00:52, 119.96it/s]\u001b[A\n",
      " 97%|█████████▋| 96875/100000 [13:01<00:25, 123.88it/s]\u001b[A\n",
      "100%|██████████| 100000/100000 [13:02<00:00, 127.79it/s]\u001b[A\n",
      "\u001b[A"
     ]
    },
    {
     "ename": "ArticleException",
     "evalue": "Article `download()` failed with 404 Client Error: Not Found for url: http://www.reuters.com/article/jpmorgan-jeffersoncounty-settlement-idUSL1N13R19F20151202 on URL http://www.reuters.com/article/jpmorgan-jeffersoncounty-settlement-idUSL1N13R19F20151202",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/Users/ruoyangzhang/anaconda3/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n    result = (True, func(*args, **kwds))\n  File \"/Users/ruoyangzhang/anaconda3/lib/python3.6/multiprocessing/pool.py\", line 44, in mapstar\n    return list(map(*args))\n  File \"<ipython-input-198-0506a6b5fb5e>\", line 6, in download_article_to_dict\n    article.parse()\n  File \"/Users/ruoyangzhang/anaconda3/lib/python3.6/site-packages/newspaper/article.py\", line 185, in parse\n    self.throw_if_not_downloaded_verbose()\n  File \"/Users/ruoyangzhang/anaconda3/lib/python3.6/site-packages/newspaper/article.py\", line 526, in throw_if_not_downloaded_verbose\n    (self.download_exception_msg, self.url))\nnewspaper.article.ArticleException: Article `download()` failed with 404 Client Error: Not Found for url: http://www.reuters.com/article/jpmorgan-jeffersoncounty-settlement-idUSL1N13R19F20151202 on URL http://www.reuters.com/article/jpmorgan-jeffersoncounty-settlement-idUSL1N13R19F20151202\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mArticleException\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-199-dc0ea253d0ce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxtasksperchild\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdownload_res\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdownload_article_to_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marticle_links\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m100000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    264\u001b[0m         \u001b[0;32min\u001b[0m \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mthat\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mreturned\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m         '''\n\u001b[0;32m--> 266\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapstar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstarmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    642\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 644\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    645\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mArticleException\u001b[0m: Article `download()` failed with 404 Client Error: Not Found for url: http://www.reuters.com/article/jpmorgan-jeffersoncounty-settlement-idUSL1N13R19F20151202 on URL http://www.reuters.com/article/jpmorgan-jeffersoncounty-settlement-idUSL1N13R19F20151202"
     ]
    }
   ],
   "source": [
    "\n",
    "p = Pool(8, maxtasksperchild=1)\n",
    "download_res = p.map(download_article_to_dict, tqdm(article_links[:1000]))\n",
    "p.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(download_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "article = Article(link)\n",
    "article.download()\n",
    "article.parse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'https://s4.reutersmedia.net/resources_v2/images/rcom-default.png'}"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article.images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
