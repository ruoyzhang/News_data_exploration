{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from scipy import spatial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the papersapce version\n",
    "data_dir_1 = '/home/paperspace/projects/news_exploration/Data/training_data/period1/'\n",
    "data_dir_0 = '/home/paperspace/projects/news_exploration/Data/training_data/period0/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the local version\n",
    "data_dir_0 = '/Users/ruoyangzhang/Documents/PythonWorkingDirectory/news_exploration/Data/training_data/period0/'\n",
    "data_dir_1 = '/Users/ruoyangzhang/Documents/PythonWorkingDirectory/news_exploration/Data/training_data/period1/'\n",
    "data_dir_2 = '/Users/ruoyangzhang/Documents/PythonWorkingDirectory/news_exploration/Data/training_data/period2/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(data_dir_0 +'word2idx.dat', 'rb') as handle:\n",
    "    word2idx_0 = pickle.load(handle)\n",
    "with open(data_dir_1 +'word2idx.dat', 'rb') as handle:\n",
    "    word2idx_1 = pickle.load(handle)\n",
    "with open(data_dir_2 +'word2idx.dat', 'rb') as handle:\n",
    "    word2idx_2 = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(data_dir_0 +'idx2word.dat', 'rb') as handle:\n",
    "    idx2word_0 = pickle.load(handle)\n",
    "with open(data_dir_1 +'idx2word.dat', 'rb') as handle:\n",
    "    idx2word_1 = pickle.load(handle)\n",
    "with open(data_dir_2 +'idx2word.dat', 'rb') as handle:\n",
    "    idx2word_2 = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(data_dir_0 +'idx2vec.dat', 'rb') as handle:\n",
    "    idx2vec_0 = pickle.load(handle)\n",
    "with open(data_dir_1 +'idx2vec.dat', 'rb') as handle:\n",
    "    idx2vec_1 = pickle.load(handle)\n",
    "with open(data_dir_2 +'idx2vec.dat', 'rb') as handle:\n",
    "    idx2vec_2 = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "class similar_words:\n",
    "    \n",
    "    def __init__(self, data_dir):\n",
    "        with open(data_dir + 'word2idx.dat', 'rb') as handle:\n",
    "            self.word2idx = pickle.load(handle)\n",
    "        with open(data_dir + 'idx2word.dat', 'rb') as handle:\n",
    "            self.idx2word = pickle.load(handle)\n",
    "        with open(data_dir + 'idx2vec.dat', 'rb') as handle:\n",
    "            self.idx2vec = pickle.load(handle)\n",
    "    \n",
    "    def normalise(self):\n",
    "        l2_norm = np.sqrt((self.idx2vec * self.idx2vec).sum(axis = 1)).reshape((self.idx2vec.shape[0]),1)\n",
    "        self.n_idx2vec = self.idx2vec/l2_norm\n",
    "        self.n_idx2vec[0] = np.array([0]*self.idx2vec.shape[1])\n",
    "        \n",
    "    \n",
    "    def closest_neighbours(self, word, n = 10, normalised = True):\n",
    "        idx = self.word2idx[word]\n",
    "        if normalised:\n",
    "            idx_sim_dict = {i:1-spatial.distance.cosine(self.n_idx2vec[idx],vec) for i,vec in enumerate(self.n_idx2vec) if i not in [0,idx]}\n",
    "        else:\n",
    "            idx_sim_dict = {i:1-spatial.distance.cosine(self.idx2vec[idx],vec) for i,vec in enumerate(self.idx2vec) if i not in [0,idx]}\n",
    "        idx_sim_dict = sorted(idx_sim_dict.items(), key=lambda kv: kv[1], reverse=True)\n",
    "        self.neighbours = [(self.idx2word[pair[0]], pair[1]) for pair in idx_sim_dict[:20]]\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neighbourhood import similar_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ruoyangzhang/Documents/PythonWorkingDirectory/news_exploration/News_data_exploration/neighbourhood.py:17: RuntimeWarning: invalid value encountered in true_divide\n",
      "  self.n_idx2vec = self.idx2vec/l2_norm\n"
     ]
    }
   ],
   "source": [
    "test0 = similar_words(data_dir_0)\n",
    "test0.normalise()\n",
    "test1 = similar_words(data_dir_1)\n",
    "test1.normalise()\n",
    "test2 = similar_words(data_dir_2)\n",
    "test2.normalise()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "word = 'brexit'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test0.closest_neighbours(word, n = 20, normalised = True)\n",
    "test1.closest_neighbours(word, n = 20, normalised = True)\n",
    "test2.closest_neighbours(word, n = 20, normalised = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('eu', 0.9391635656356812),\n",
       " ('britain', 0.9367096424102783),\n",
       " ('referendum', 0.9336940050125122),\n",
       " ('exit', 0.9305105805397034),\n",
       " ('uk', 0.9281169176101685),\n",
       " ('european_union', 0.9156014323234558),\n",
       " ('britons', 0.9055400490760803),\n",
       " ('voting', 0.8957501649856567),\n",
       " ('tomorrow', 0.8924056887626648),\n",
       " ('independence', 0.8921576142311096),\n",
       " ('ahead', 0.8837446570396423),\n",
       " ('leaving', 0.8815494775772095),\n",
       " ('open', 0.8773015141487122),\n",
       " ('impact', 0.8771299123764038),\n",
       " ('uncertainty', 0.8765949606895447),\n",
       " ('outcome', 0.8720663785934448),\n",
       " ('editorial', 0.8691046833992004),\n",
       " ('polls', 0.8688691854476929),\n",
       " ('british', 0.8677313327789307),\n",
       " ('stay', 0.8669856190681458)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test0.neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('exit', 0.944815993309021),\n",
       " ('eu', 0.9423159956932068),\n",
       " ('britain', 0.9414730072021484),\n",
       " ('referendum', 0.9360533952713013),\n",
       " ('uk', 0.9328083395957947),\n",
       " ('european_union', 0.9217364192008972),\n",
       " ('britons', 0.9167843461036682),\n",
       " ('voting', 0.9102171063423157),\n",
       " ('tomorrow', 0.9101792573928833),\n",
       " ('goafter', 0.899278998374939),\n",
       " ('scottish_independence', 0.8978261351585388),\n",
       " ('independence', 0.8973746299743652),\n",
       " ('continue_apacebrexit', 0.8971027135848999),\n",
       " ('outcome', 0.890224039554596),\n",
       " ('uncertainty', 0.887132465839386),\n",
       " ('editorial', 0.8868875503540039),\n",
       " ('polls', 0.8803579211235046),\n",
       " ('predict', 0.8770049214363098),\n",
       " ('british', 0.8749314546585083),\n",
       " ('snp_won', 0.8748005032539368)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test1.neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('britain', 0.9449349045753479),\n",
       " ('eu', 0.9430117607116699),\n",
       " ('exit', 0.9397880434989929),\n",
       " ('referendum', 0.9390013217926025),\n",
       " ('uk', 0.9333792924880981),\n",
       " ('voting', 0.9219726324081421),\n",
       " ('european_union', 0.9217431545257568),\n",
       " ('britons', 0.9187378883361816),\n",
       " ('polls', 0.8933077454566956),\n",
       " ('results', 0.8812395930290222),\n",
       " ('outcome', 0.8773514032363892),\n",
       " ('british', 0.8712339997291565),\n",
       " ('affect', 0.8684083819389343),\n",
       " ('u_k', 0.866401731967926),\n",
       " ('voter', 0.8662026524543762),\n",
       " ('independence', 0.8653834462165833),\n",
       " ('membership', 0.8650548458099365),\n",
       " ('tomorrow', 0.8636869192123413),\n",
       " ('ahead', 0.858947217464447),\n",
       " ('uncertainty', 0.8586441874504089)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test2.neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "top10_0 = set([pair[0] for pair in test0.neighbours])\n",
    "top10_1 = set([pair[0] for pair in test1.neighbours])\n",
    "top10_2 = set([pair[0] for pair in test2.neighbours])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'asaad',\n",
       " 'baal_shamin',\n",
       " 'cambodian_border',\n",
       " 'drone_strikes',\n",
       " 'jordanian',\n",
       " 'shia'}"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top10_0 - top10_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'airstrikes', 'antiquities', 'gruesome', 'libya', 'militants', 'sunni'}"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top10_1 - top10_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'baghdadi', 'gruesome', 'militants', 'torture'}"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top10_1 - top10_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'iraqi', 'isis_militants', 'palmyra', 'tortured'}"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top10_2 - top10_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does not look like it's converged/overfit after only 3 epochs of training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## testing converting articles to images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dict = test.n_idx2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dict[0] = np.array([0]*300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/paperspace/projects/news_exploration/Data/all-the-news/' + 'articles_1_0_preprocessed.pickle', 'rb') as handle:\n",
    "    articles = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "article1 = articles[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_idx(word):\n",
    "    if word in word2idx_0.keys():\n",
    "        return(word2idx_0[word])\n",
    "    else:\n",
    "        return(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "article1_tok = [return_idx(word) for word in article1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "article1_img = np.array([img_dict[tok] for tok in article1_tok])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_val = min([min(elem) for elem in article1_img])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "article1_img_shift = article1_img - min_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2_norm = np.sqrt((article1_img_shift*article1_img_shift).sum(axis = 1)).reshape(703,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "article1_img_shift_norm = article1_img_shift/l2_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_val = max([max(tok) for tok in article1_img_shift_norm])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "article1_img_shift_norm_scaled = article1_img_shift_norm/max_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "heatmap = cv2.applyColorMap(np.uint8(255*article1_img_shift_norm_scaled), cv2.COLORMAP_JET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imwrite(data_dir_0+\"article_1.jpg\", np.uint8(255 * heatmap))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
