{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from scipy import spatial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the papersapce version\n",
    "data_dir_1 = '/home/paperspace/projects/news_exploration/Data/training_data/period1/'\n",
    "data_dir_0 = '/home/paperspace/projects/news_exploration/Data/training_data/period0/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the local version\n",
    "data_dir_0 = '/Users/ruoyangzhang/Documents/PythonWorkingDirectory/news_exploration/Data/training_data/period0/'\n",
    "data_dir_1 = '/Users/ruoyangzhang/Documents/PythonWorkingDirectory/news_exploration/Data/training_data/period1/'\n",
    "data_dir_2 = '/Users/ruoyangzhang/Documents/PythonWorkingDirectory/news_exploration/Data/training_data/period2/'\n",
    "data_dir_3 = '/Users/ruoyangzhang/Documents/PythonWorkingDirectory/news_exploration/Data/training_data/period3/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(data_dir_0 +'word2idx.dat', 'rb') as handle:\n",
    "    word2idx_0 = pickle.load(handle)\n",
    "with open(data_dir_1 +'word2idx.dat', 'rb') as handle:\n",
    "    word2idx_1 = pickle.load(handle)\n",
    "with open(data_dir_2 +'word2idx.dat', 'rb') as handle:\n",
    "    word2idx_2 = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(data_dir_0 +'idx2word.dat', 'rb') as handle:\n",
    "    idx2word_0 = pickle.load(handle)\n",
    "with open(data_dir_1 +'idx2word.dat', 'rb') as handle:\n",
    "    idx2word_1 = pickle.load(handle)\n",
    "with open(data_dir_2 +'idx2word.dat', 'rb') as handle:\n",
    "    idx2word_2 = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(data_dir_0 +'idx2vec.dat', 'rb') as handle:\n",
    "    idx2vec_0 = pickle.load(handle)\n",
    "with open(data_dir_1 +'idx2vec.dat', 'rb') as handle:\n",
    "    idx2vec_1 = pickle.load(handle)\n",
    "with open(data_dir_2 +'idx2vec.dat', 'rb') as handle:\n",
    "    idx2vec_2 = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "class similar_words:\n",
    "    \n",
    "    def __init__(self, data_dir):\n",
    "        with open(data_dir + 'word2idx.dat', 'rb') as handle:\n",
    "            self.word2idx = pickle.load(handle)\n",
    "        with open(data_dir + 'idx2word.dat', 'rb') as handle:\n",
    "            self.idx2word = pickle.load(handle)\n",
    "        with open(data_dir + 'idx2vec.dat', 'rb') as handle:\n",
    "            self.idx2vec = pickle.load(handle)\n",
    "    \n",
    "    def normalise(self):\n",
    "        l2_norm = np.sqrt((self.idx2vec * self.idx2vec).sum(axis = 1)).reshape((self.idx2vec.shape[0]),1)\n",
    "        self.n_idx2vec = self.idx2vec/l2_norm\n",
    "        self.n_idx2vec[0] = np.array([0]*self.idx2vec.shape[1])\n",
    "        \n",
    "    \n",
    "    def closest_neighbours(self, word, n = 10, normalised = True):\n",
    "        idx = self.word2idx[word]\n",
    "        if normalised:\n",
    "            idx_sim_dict = {i:1-spatial.distance.cosine(self.n_idx2vec[idx],vec) for i,vec in enumerate(self.n_idx2vec) if i not in [0,idx]}\n",
    "        else:\n",
    "            idx_sim_dict = {i:1-spatial.distance.cosine(self.idx2vec[idx],vec) for i,vec in enumerate(self.idx2vec) if i not in [0,idx]}\n",
    "        idx_sim_dict = sorted(idx_sim_dict.items(), key=lambda kv: kv[1], reverse=True)\n",
    "        self.neighbours = [(self.idx2word[pair[0]], pair[1]) for pair in idx_sim_dict[:20]]\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neighbourhood import similar_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ruoyangzhang/Documents/PythonWorkingDirectory/news_exploration/News_data_exploration/neighbourhood.py:17: RuntimeWarning: invalid value encountered in true_divide\n",
      "  self.n_idx2vec = self.idx2vec/l2_norm\n"
     ]
    }
   ],
   "source": [
    "test0 = similar_words(data_dir_0)\n",
    "test0.normalise()\n",
    "test1 = similar_words(data_dir_1)\n",
    "test1.normalise()\n",
    "test2 = similar_words(data_dir_2)\n",
    "test2.normalise()\n",
    "test3 = similar_words(data_dir_3)\n",
    "test3.normalise()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "word = 'brexit'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "test0.closest_neighbours(word, n = 20, normalised = True)\n",
    "test1.closest_neighbours(word, n = 20, normalised = True)\n",
    "test2.closest_neighbours(word, n = 20, normalised = True)\n",
    "test3.closest_neighbours(word, n = 20, normalised = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('choice', 0.999566376209259),\n",
       " ('controls', 0.999552845954895),\n",
       " ('benefits', 0.999545156955719),\n",
       " ('ideas', 0.9995364546775818),\n",
       " ('disunity', 0.999534010887146),\n",
       " ('spend', 0.9995262026786804),\n",
       " ('once_again', 0.9995113611221313),\n",
       " ('specific', 0.999505877494812),\n",
       " ('hillary', 0.9994996190071106),\n",
       " ('thiel', 0.9994985461235046),\n",
       " ('reason', 0.999496579170227),\n",
       " ('likely', 0.9994961619377136),\n",
       " ('felt', 0.9994959831237793),\n",
       " ('chance', 0.9994956851005554),\n",
       " ('grow', 0.999494194984436),\n",
       " ('however', 0.9994904398918152),\n",
       " ('coming', 0.9994888305664062),\n",
       " ('accept', 0.999488115310669),\n",
       " ('tried', 0.999487042427063),\n",
       " ('daya', 0.9994818568229675)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test0.neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('respected', 0.9995054602622986),\n",
       " ('benefits', 0.9995003938674927),\n",
       " ('vast_majority', 0.9994900226593018),\n",
       " ('politically', 0.9994823336601257),\n",
       " ('institutions', 0.9994748830795288),\n",
       " ('allowing', 0.9994727969169617),\n",
       " ('choice', 0.9994722008705139),\n",
       " ('extent', 0.9994635581970215),\n",
       " ('demands', 0.9994620084762573),\n",
       " ('forming', 0.9994614124298096),\n",
       " ('respective', 0.9994603395462036),\n",
       " ('austerity', 0.9994600415229797),\n",
       " ('walker', 0.9994565844535828),\n",
       " ('uncertainty', 0.9994453191757202),\n",
       " ('discuss', 0.9994413256645203),\n",
       " ('elective', 0.9994373917579651),\n",
       " ('coming', 0.9994370937347412),\n",
       " ('movements', 0.9994354248046875),\n",
       " ('ads', 0.9994299411773682),\n",
       " ('depending', 0.999428927898407)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test1.neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('mandates', 0.9994180798530579),\n",
       " ('bodies', 0.9994128942489624),\n",
       " ('benefit', 0.999407947063446),\n",
       " ('edge', 0.9993902444839478),\n",
       " ('responsibility', 0.9993853569030762),\n",
       " ('ticket', 0.9993813037872314),\n",
       " ('ideas', 0.999373733997345),\n",
       " ('inability', 0.9993717670440674),\n",
       " ('friday_morning', 0.999365508556366),\n",
       " ('institutions', 0.9993582367897034),\n",
       " ('debated', 0.9993510246276855),\n",
       " ('escape', 0.9993463754653931),\n",
       " ('amount', 0.9993341565132141),\n",
       " ('represent', 0.9993335604667664),\n",
       " ('enforce', 0.9993295073509216),\n",
       " ('effective', 0.9993287324905396),\n",
       " ('bulk', 0.9993284940719604),\n",
       " ('voter', 0.9993267059326172),\n",
       " ('thus', 0.999326229095459),\n",
       " ('pull', 0.9993253350257874)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test2.neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('snp_won', 0.9989718198776245),\n",
       " ('system', 0.9989229440689087),\n",
       " ('benefit', 0.9988568425178528),\n",
       " ('uncertainty', 0.9987775683403015),\n",
       " ('next', 0.9987561702728271),\n",
       " ('relationship', 0.9987049102783203),\n",
       " ('exit', 0.998687207698822),\n",
       " ('expected', 0.9986510276794434),\n",
       " ('special_relationship', 0.9986289739608765),\n",
       " ('responsibility', 0.9986240267753601),\n",
       " ('amount', 0.9985915422439575),\n",
       " ('closer', 0.9985849261283875),\n",
       " ('lbc', 0.9985722899436951),\n",
       " ('inability', 0.9985594153404236),\n",
       " ('binding', 0.9985369443893433),\n",
       " ('count', 0.9985288381576538),\n",
       " ('however', 0.998528778553009),\n",
       " ('leaves', 0.9985228180885315),\n",
       " ('outcome', 0.9985215067863464),\n",
       " ('allowing', 0.9985187649726868)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test3.neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "top10_0 = set([pair[0] for pair in test0.neighbours])\n",
    "top10_1 = set([pair[0] for pair in test1.neighbours])\n",
    "top10_2 = set([pair[0] for pair in test2.neighbours])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'debate', 'lead', 'thursday', 'win'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top10_0 - top10_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'britons', 'tomorrow', 'u_k', 'united_kingdom'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top10_1 - top10_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ahead', 'independence', 'tomorrow'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top10_1 - top10_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'debate', 'voted', 'win'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top10_2 - top10_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does not look like it's converged/overfit after only 3 epochs of training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## testing converting articles to images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dict = test.n_idx2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dict[0] = np.array([0]*300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/paperspace/projects/news_exploration/Data/all-the-news/' + 'articles_1_0_preprocessed.pickle', 'rb') as handle:\n",
    "    articles = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "article1 = articles[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_idx(word):\n",
    "    if word in word2idx_0.keys():\n",
    "        return(word2idx_0[word])\n",
    "    else:\n",
    "        return(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "article1_tok = [return_idx(word) for word in article1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "article1_img = np.array([img_dict[tok] for tok in article1_tok])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_val = min([min(elem) for elem in article1_img])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "article1_img_shift = article1_img - min_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2_norm = np.sqrt((article1_img_shift*article1_img_shift).sum(axis = 1)).reshape(703,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "article1_img_shift_norm = article1_img_shift/l2_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_val = max([max(tok) for tok in article1_img_shift_norm])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "article1_img_shift_norm_scaled = article1_img_shift_norm/max_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "heatmap = cv2.applyColorMap(np.uint8(255*article1_img_shift_norm_scaled), cv2.COLORMAP_JET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imwrite(data_dir_0+\"article_1.jpg\", np.uint8(255 * heatmap))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
