{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from scipy import spatial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the papersapce version\n",
    "data_dir_1 = '/home/paperspace/projects/news_exploration/Data/training_data/period1/'\n",
    "data_dir_0 = '/home/paperspace/projects/news_exploration/Data/training_data/period0/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the local version\n",
    "data_dir_0 = '/Users/ruoyangzhang/Documents/PythonWorkingDirectory/news_exploration/Data/training_data/period0/'\n",
    "data_dir_1 = '/Users/ruoyangzhang/Documents/PythonWorkingDirectory/news_exploration/Data/training_data/period1/'\n",
    "data_dir_2 = '/Users/ruoyangzhang/Documents/PythonWorkingDirectory/news_exploration/Data/training_data/period2/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(data_dir_0 +'word2idx.dat', 'rb') as handle:\n",
    "    word2idx_0 = pickle.load(handle)\n",
    "with open(data_dir_1 +'word2idx.dat', 'rb') as handle:\n",
    "    word2idx_1 = pickle.load(handle)\n",
    "with open(data_dir_2 +'word2idx.dat', 'rb') as handle:\n",
    "    word2idx_2 = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(data_dir_0 +'idx2word.dat', 'rb') as handle:\n",
    "    idx2word_0 = pickle.load(handle)\n",
    "with open(data_dir_1 +'idx2word.dat', 'rb') as handle:\n",
    "    idx2word_1 = pickle.load(handle)\n",
    "with open(data_dir_2 +'idx2word.dat', 'rb') as handle:\n",
    "    idx2word_2 = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(data_dir_0 +'idx2vec.dat', 'rb') as handle:\n",
    "    idx2vec_0 = pickle.load(handle)\n",
    "with open(data_dir_1 +'idx2vec.dat', 'rb') as handle:\n",
    "    idx2vec_1 = pickle.load(handle)\n",
    "with open(data_dir_2 +'idx2vec.dat', 'rb') as handle:\n",
    "    idx2vec_2 = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "class similar_words:\n",
    "    \n",
    "    def __init__(self, data_dir):\n",
    "        with open(data_dir + 'word2idx.dat', 'rb') as handle:\n",
    "            self.word2idx = pickle.load(handle)\n",
    "        with open(data_dir + 'idx2word.dat', 'rb') as handle:\n",
    "            self.idx2word = pickle.load(handle)\n",
    "        with open(data_dir + 'idx2vec.dat', 'rb') as handle:\n",
    "            self.idx2vec = pickle.load(handle)\n",
    "    \n",
    "    def normalise(self):\n",
    "        l2_norm = np.sqrt((self.idx2vec * self.idx2vec).sum(axis = 1)).reshape((self.idx2vec.shape[0]),1)\n",
    "        self.n_idx2vec = self.idx2vec/l2_norm\n",
    "        self.n_idx2vec[0] = np.array([0]*self.idx2vec.shape[1])\n",
    "        \n",
    "    \n",
    "    def closest_neighbours(self, word, n = 10, normalised = True):\n",
    "        idx = self.word2idx[word]\n",
    "        if normalised:\n",
    "            idx_sim_dict = {i:1-spatial.distance.cosine(self.n_idx2vec[idx],vec) for i,vec in enumerate(self.n_idx2vec) if i not in [0,idx]}\n",
    "        else:\n",
    "            idx_sim_dict = {i:1-spatial.distance.cosine(self.idx2vec[idx],vec) for i,vec in enumerate(self.idx2vec) if i not in [0,idx]}\n",
    "        idx_sim_dict = sorted(idx_sim_dict.items(), key=lambda kv: kv[1], reverse=True)\n",
    "        self.neighbours = [(self.idx2word[pair[0]], pair[1]) for pair in idx_sim_dict[:20]]\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neighbourhood import similar_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "test0 = similar_words(data_dir_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ruoyangzhang/Documents/PythonWorkingDirectory/news_exploration/News_data_exploration/neighbourhood.py:17: RuntimeWarning: invalid value encountered in true_divide\n",
      "  self.n_idx2vec = self.idx2vec/l2_norm\n"
     ]
    }
   ],
   "source": [
    "test0.normalise()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "word = 'fashion'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "test0.closest_neighbours(word, n = 20, normalised = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('décor', 0.473824143409729),\n",
       " ('dior', 0.4666462540626526),\n",
       " ('apparel', 0.4506337344646454),\n",
       " ('bridal', 0.4490150809288025),\n",
       " ('runway', 0.44382429122924805),\n",
       " ('clothing', 0.44152820110321045),\n",
       " ('couture', 0.43641987442970276),\n",
       " ('handbags', 0.43607690930366516),\n",
       " ('neiman_marcus', 0.4355430006980896),\n",
       " ('trendy', 0.4320079982280731),\n",
       " ('designer', 0.43141472339630127),\n",
       " ('beauty', 0.4302421808242798),\n",
       " ('glamour', 0.41984882950782776),\n",
       " ('wardrobe', 0.41588902473449707),\n",
       " ('topless', 0.41465774178504944),\n",
       " ('interiors', 0.41364941000938416),\n",
       " ('timeless', 0.41271910071372986),\n",
       " ('footwear', 0.41215482354164124),\n",
       " ('fashionable', 0.4108976721763611),\n",
       " ('captivated', 0.40991440415382385)]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test0.neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ruoyangzhang/Documents/PythonWorkingDirectory/news_exploration/News_data_exploration/neighbourhood.py:17: RuntimeWarning: invalid value encountered in true_divide\n",
      "  self.n_idx2vec = self.idx2vec/l2_norm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('menswear', 0.5523653626441956),\n",
       " ('décor', 0.47711968421936035),\n",
       " ('dior', 0.46622470021247864),\n",
       " ('handbags', 0.4616985321044922),\n",
       " ('apparel', 0.4595603346824646),\n",
       " ('bridal', 0.45153290033340454),\n",
       " ('runway', 0.45103034377098083),\n",
       " ('couture', 0.44893360137939453),\n",
       " ('clothing', 0.4433886408805847),\n",
       " ('alexander_wang', 0.439322292804718),\n",
       " ('designer', 0.43929076194763184),\n",
       " ('trendy', 0.4361766576766968),\n",
       " ('neiman_marcus', 0.43375322222709656),\n",
       " ('beauty', 0.4307521879673004),\n",
       " ('captivated', 0.42773011326789856),\n",
       " ('wardrobe', 0.4221920073032379),\n",
       " ('glamour', 0.4221176505088806),\n",
       " ('footwear', 0.42209333181381226),\n",
       " ('timeless', 0.4201917052268982),\n",
       " ('fashionable', 0.41839972138404846)]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test1 = similar_words(data_dir_1)\n",
    "test1.normalise()\n",
    "test1.closest_neighbours(word, n = 20, normalised = True)\n",
    "test1.neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ruoyangzhang/Documents/PythonWorkingDirectory/news_exploration/News_data_exploration/neighbourhood.py:17: RuntimeWarning: invalid value encountered in true_divide\n",
      "  self.n_idx2vec = self.idx2vec/l2_norm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('dior', 0.4696812927722931),\n",
       " ('handbags', 0.46053552627563477),\n",
       " ('bridal', 0.45908769965171814),\n",
       " ('apparel', 0.45756790041923523),\n",
       " ('clothing', 0.4505559206008911),\n",
       " ('designer', 0.4469684660434723),\n",
       " ('runway', 0.4434295892715454),\n",
       " ('couture', 0.43874359130859375),\n",
       " ('trendy', 0.4379028379917145),\n",
       " ('neiman_marcus', 0.43745315074920654),\n",
       " ('beauty', 0.4352210462093353),\n",
       " ('footwear', 0.4325682818889618),\n",
       " ('fashionable', 0.4302198886871338),\n",
       " ('wardrobe', 0.4250568151473999),\n",
       " ('sephora', 0.424826979637146),\n",
       " ('glamour', 0.4241793751716614),\n",
       " ('entertainment', 0.4119870364665985),\n",
       " ('timeless', 0.4118971526622772),\n",
       " ('pop_culture', 0.40855884552001953),\n",
       " ('fashions', 0.4047462046146393)]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test2 = similar_words(data_dir_2)\n",
    "test2.normalise()\n",
    "test2.closest_neighbours(word, n = 20, normalised = True)\n",
    "test2.neighbours"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does not look like it's converged/overfit after only 3 epochs of training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## testing converting articles to images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dict = test.n_idx2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dict[0] = np.array([0]*300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/paperspace/projects/news_exploration/Data/all-the-news/' + 'articles_1_0_preprocessed.pickle', 'rb') as handle:\n",
    "    articles = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "article1 = articles[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_idx(word):\n",
    "    if word in word2idx_0.keys():\n",
    "        return(word2idx_0[word])\n",
    "    else:\n",
    "        return(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "article1_tok = [return_idx(word) for word in article1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "article1_img = np.array([img_dict[tok] for tok in article1_tok])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_val = min([min(elem) for elem in article1_img])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "article1_img_shift = article1_img - min_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2_norm = np.sqrt((article1_img_shift*article1_img_shift).sum(axis = 1)).reshape(703,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "article1_img_shift_norm = article1_img_shift/l2_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_val = max([max(tok) for tok in article1_img_shift_norm])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "article1_img_shift_norm_scaled = article1_img_shift_norm/max_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "heatmap = cv2.applyColorMap(np.uint8(255*article1_img_shift_norm_scaled), cv2.COLORMAP_JET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imwrite(data_dir_0+\"article_1.jpg\", np.uint8(255 * heatmap))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
