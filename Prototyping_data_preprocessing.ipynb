{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from collections import defaultdict\n",
    "import datetime\n",
    "from tqdm import tqdm\n",
    "import spacy\n",
    "from multiprocessing import Pool\n",
    "import pickle\n",
    "import string\n",
    "\n",
    "data_path = '../Data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_1 = pd.read_csv(data_path + 'all-the-news/articles1.csv', encoding = 'utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_1 = data_1.drop(['Unnamed: 0'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>publication</th>\n",
       "      <th>author</th>\n",
       "      <th>date</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>url</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17283</td>\n",
       "      <td>House Republicans Fret About Winning Their Hea...</td>\n",
       "      <td>New York Times</td>\n",
       "      <td>Carl Hulse</td>\n",
       "      <td>2016-12-31</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WASHINGTON  —   Congressional Republicans have...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17284</td>\n",
       "      <td>Rift Between Officers and Residents as Killing...</td>\n",
       "      <td>New York Times</td>\n",
       "      <td>Benjamin Mueller and Al Baker</td>\n",
       "      <td>2017-06-19</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>After the bullet shells get counted, the blood...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17285</td>\n",
       "      <td>Tyrus Wong, ‘Bambi’ Artist Thwarted by Racial ...</td>\n",
       "      <td>New York Times</td>\n",
       "      <td>Margalit Fox</td>\n",
       "      <td>2017-01-06</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>When Walt Disney’s “Bambi” opened in 1942, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17286</td>\n",
       "      <td>Among Deaths in 2016, a Heavy Toll in Pop Musi...</td>\n",
       "      <td>New York Times</td>\n",
       "      <td>William McDonald</td>\n",
       "      <td>2017-04-10</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Death may be the great equalizer, but it isn’t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17287</td>\n",
       "      <td>Kim Jong-un Says North Korea Is Preparing to T...</td>\n",
       "      <td>New York Times</td>\n",
       "      <td>Choe Sang-Hun</td>\n",
       "      <td>2017-01-02</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SEOUL, South Korea  —   North Korea’s leader, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                              title     publication  \\\n",
       "0  17283  House Republicans Fret About Winning Their Hea...  New York Times   \n",
       "1  17284  Rift Between Officers and Residents as Killing...  New York Times   \n",
       "2  17285  Tyrus Wong, ‘Bambi’ Artist Thwarted by Racial ...  New York Times   \n",
       "3  17286  Among Deaths in 2016, a Heavy Toll in Pop Musi...  New York Times   \n",
       "4  17287  Kim Jong-un Says North Korea Is Preparing to T...  New York Times   \n",
       "\n",
       "                          author        date    year  month  url  \\\n",
       "0                     Carl Hulse  2016-12-31  2016.0   12.0  NaN   \n",
       "1  Benjamin Mueller and Al Baker  2017-06-19  2017.0    6.0  NaN   \n",
       "2                   Margalit Fox  2017-01-06  2017.0    1.0  NaN   \n",
       "3               William McDonald  2017-04-10  2017.0    4.0  NaN   \n",
       "4                  Choe Sang-Hun  2017-01-02  2017.0    1.0  NaN   \n",
       "\n",
       "                                             content  \n",
       "0  WASHINGTON  —   Congressional Republicans have...  \n",
       "1  After the bullet shells get counted, the blood...  \n",
       "2  When Walt Disney’s “Bambi” opened in 1942, cri...  \n",
       "3  Death may be the great equalizer, but it isn’t...  \n",
       "4  SEOUL, South Korea  —   North Korea’s leader, ...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preprocessing and repartition\n",
    "\n",
    "- remove punctuations\n",
    "- lower case everything\n",
    "- reduce consecutive white spaces\n",
    "- tokenisation\n",
    "\n",
    "\n",
    "\n",
    "we repartition the data into intervals of 7 days with a padding period of 23 days:\n",
    "\n",
    "- this means that for one period, we have 30 days of articles\n",
    "- the padding is there to ensure the smooth transition between periods\n",
    "- as well as to ensure we have just slightly more volume, since it is recommended to apply W2V on sufficiently large datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_1.date = [datetime.datetime.strptime(day, '%Y-%m-%d') for day in data_1.date]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We filter the data to only focus on data from 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_1 = data_1[[str(day).split('-')[0] == '2016' for day in data_1.date]].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "remove all non alpha numeric characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28451/28451 [02:13<00:00, 213.81it/s]\n"
     ]
    }
   ],
   "source": [
    "p = Pool(8, maxtasksperchild=1)\n",
    "tks_1 = p.map(nlp.tokenizer, tqdm(data_1.content))\n",
    "p.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data_1.content = [re.sub('[\\W_]+', ' ', text).lower().strip() for text in tqdm(data_1.content)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We repartition the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_date = min(data_1.date)\n",
    "max_date = max(data_1.date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Timestamp('2016-01-01 00:00:00'), Timestamp('2016-12-31 00:00:00'))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_date, max_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/47 [00:00<?, ?it/s]\u001b[A\n",
      "  2%|▏         | 1/47 [00:00<00:09,  4.77it/s]\u001b[A\n",
      "  4%|▍         | 2/47 [00:00<00:20,  2.20it/s]\u001b[A\n",
      "  6%|▋         | 3/47 [00:01<00:16,  2.70it/s]\u001b[A\n",
      "  9%|▊         | 4/47 [00:01<00:14,  3.06it/s]\u001b[A\n",
      " 11%|█         | 5/47 [00:01<00:12,  3.38it/s]\u001b[A\n",
      " 13%|█▎        | 6/47 [00:02<00:15,  2.56it/s]\u001b[A\n",
      " 15%|█▍        | 7/47 [00:02<00:14,  2.75it/s]\u001b[A\n",
      " 17%|█▋        | 8/47 [00:02<00:13,  2.95it/s]\u001b[A\n",
      " 19%|█▉        | 9/47 [00:02<00:12,  3.12it/s]\u001b[A\n",
      " 21%|██▏       | 10/47 [00:03<00:13,  2.74it/s]\u001b[A\n",
      " 23%|██▎       | 11/47 [00:03<00:12,  2.89it/s]\u001b[A\n",
      " 26%|██▌       | 12/47 [00:03<00:11,  3.02it/s]\u001b[A\n",
      " 28%|██▊       | 13/47 [00:04<00:12,  2.72it/s]\u001b[A\n",
      " 30%|██▉       | 14/47 [00:04<00:11,  2.84it/s]\u001b[A\n",
      " 32%|███▏      | 15/47 [00:05<00:10,  2.95it/s]\u001b[A\n",
      " 34%|███▍      | 16/47 [00:05<00:10,  3.03it/s]\u001b[A\n",
      " 36%|███▌      | 17/47 [00:06<00:10,  2.78it/s]\u001b[A\n",
      " 38%|███▊      | 18/47 [00:06<00:10,  2.87it/s]\u001b[A\n",
      " 40%|████      | 19/47 [00:06<00:09,  2.96it/s]\u001b[A\n",
      " 43%|████▎     | 20/47 [00:06<00:08,  3.04it/s]\u001b[A\n",
      " 45%|████▍     | 21/47 [00:07<00:09,  2.84it/s]\u001b[A\n",
      " 47%|████▋     | 22/47 [00:07<00:08,  2.91it/s]\u001b[A\n",
      " 49%|████▉     | 23/47 [00:07<00:08,  2.98it/s]\u001b[A\n",
      " 51%|█████     | 24/47 [00:07<00:07,  3.05it/s]\u001b[A\n",
      " 53%|█████▎    | 25/47 [00:08<00:07,  2.89it/s]\u001b[A\n",
      " 55%|█████▌    | 26/47 [00:08<00:07,  2.96it/s]\u001b[A\n",
      " 57%|█████▋    | 27/47 [00:08<00:06,  3.02it/s]\u001b[A\n",
      " 60%|█████▉    | 28/47 [00:09<00:06,  3.09it/s]\u001b[A\n",
      " 62%|██████▏   | 29/47 [00:09<00:06,  2.96it/s]\u001b[A\n",
      " 64%|██████▍   | 30/47 [00:09<00:05,  3.02it/s]\u001b[A\n",
      " 66%|██████▌   | 31/47 [00:10<00:05,  3.08it/s]\u001b[A\n",
      " 68%|██████▊   | 32/47 [00:10<00:04,  3.13it/s]\u001b[A\n",
      " 70%|███████   | 33/47 [00:11<00:04,  3.00it/s]\u001b[A\n",
      " 72%|███████▏  | 34/47 [00:11<00:04,  3.04it/s]\u001b[A\n",
      " 74%|███████▍  | 35/47 [00:11<00:03,  3.09it/s]\u001b[A\n",
      " 77%|███████▋  | 36/47 [00:11<00:03,  3.13it/s]\u001b[A\n",
      " 79%|███████▊  | 37/47 [00:12<00:03,  3.01it/s]\u001b[A\n",
      " 81%|████████  | 38/47 [00:12<00:02,  3.05it/s]\u001b[A\n",
      " 83%|████████▎ | 39/47 [00:12<00:02,  3.10it/s]\u001b[A\n",
      " 85%|████████▌ | 40/47 [00:13<00:02,  3.00it/s]\u001b[A\n",
      " 87%|████████▋ | 41/47 [00:13<00:01,  3.05it/s]\u001b[A\n",
      " 89%|████████▉ | 42/47 [00:13<00:01,  3.10it/s]\u001b[A\n",
      " 91%|█████████▏| 43/47 [00:13<00:01,  3.15it/s]\u001b[A\n",
      " 94%|█████████▎| 44/47 [00:14<00:00,  3.05it/s]\u001b[A\n",
      " 96%|█████████▌| 45/47 [00:14<00:00,  3.10it/s]\u001b[A\n",
      " 98%|█████████▊| 46/47 [00:14<00:00,  3.14it/s]\u001b[A\n",
      "100%|██████████| 47/47 [00:14<00:00,  3.19it/s]\u001b[A\n",
      "\u001b[A"
     ]
    }
   ],
   "source": [
    "# we could parallelise/multithread this process if the datasets are much bigger\n",
    "begin_date = min_date\n",
    "repartitioned_articles = []\n",
    "for i in tqdm(range(int((int((max_date - min_date).days) - 30) / 7))):\n",
    "    articles = data_1[[begin_date <= day < begin_date + datetime.timedelta(days = 30) for day in data_1.date]].content\n",
    "    #with open(data_path+'all-the-news/articles_1_preprocessed.txt', 'w') as f:\n",
    "    #    for article in articles:\n",
    "    #       f.write(' '.join(article) + ' \\n')\n",
    "    begin_date += datetime.timedelta(days = 7)\n",
    "    repartitioned_articles.append(articles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We pickle the above file for later use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(data_path+'all-the-news/articles_1_preprocessed.pickle', 'wb') as handle:\n",
    "    pickle.dump(repartitioned_articles, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(data_path+'all-the-news/articles_1_preprocessed.pickle', 'rb') as handle:\n",
    "    df = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing out the class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing import news_preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepro = news_preprocess(cores = 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17908/17908 [01:41<00:00, 176.62it/s]\n",
      "100%|██████████| 17908/17908 [00:52<00:00, 340.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the dataframe is preprocessed successfully\n"
     ]
    }
   ],
   "source": [
    "data_dir = '../Data/all-the-news/articles1.csv'\n",
    "prepro.pre_process(data_dir, 'content', 'date', begin = 20170101, end = 20171231)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:02<00:00,  8.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "articles repartitioned, they can be accessed at self.reparitioned_articles\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "prepro.cut_and_slide(30,7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepro.save_to_pickle(data_path+'all-the-news/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(data_path + 'articles_1_preprocessed.pickle', 'rb') as handle:\n",
    "    article_lst = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "success"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
